#!/usr/bin/env python3
"""
scripts/fetch_boj_problem.py
ë°±ì¤€ì—ì„œ ë¬¸ì œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (requests + BeautifulSoup ë°©ì‹ - ì•ˆì •ì !)
GitHub Actionsì™€ ë¡œì»¬ í™˜ê²½ ëª¨ë‘ì—ì„œ ì™„ë²½ ì‘ë™
"""

import argparse
import json
import requests
from bs4 import BeautifulSoup
import time 
import os

def get_solved_ac_info(problem_id):
    """solved.ac APIì—ì„œ ë¬¸ì œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        url = f"https://solved.ac/api/v3/problem/show?problemId={problem_id}"
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        if response.status_code == 200:
            data = response.json()
            tags = []
            for tag in data.get("tags", []):
                korean_tag = next((item['name'] for item in tag.get('displayNames', []) if item['language'] == 'ko'), None)
                if korean_tag:
                    tags.append(korean_tag)
            
            return {
                "title": data.get("titleKo", ""),
                "level": data.get("level", 0),
                "tags": tags
            }
    except Exception as e:
        print(f"  âš ï¸ solved.ac API ì˜¤ë¥˜: {e}")
    
    return {}

def extract_problem_info_from_html(html_content):
    """HTMLì—ì„œ ë¬¸ì œ ì •ë³´ ì¶”ì¶œ"""
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # ë¬¸ì œê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì²´í¬
    if "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¬¸ì œ" in soup.text or "í•´ë‹¹ ë¬¸ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in soup.text:
        print("  âŒ ë¬¸ì œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None

    problem_info = {}
    
    # 1. ë¬¸ì œ ì„¤ëª…
    desc_section = soup.find('section', {'id': 'description'})
    if desc_section:
        problem_info['description'] = desc_section.get_text(separator='\n', strip=True)
        print("  âœ… ë¬¸ì œ ì„¤ëª… ì¶”ì¶œ ì™„ë£Œ")
    else:
        desc_elem = soup.find('div', {'id': 'problem_description'})
        problem_info['description'] = desc_elem.get_text(separator='\n', strip=True) if desc_elem else ""
    
    # 2. ì…ë ¥ ì„¤ëª…
    input_section = soup.find('section', {'id': 'input'})
    if input_section:
        problem_info['input_format'] = input_section.get_text(separator='\n', strip=True)
        print("  âœ… ì…ë ¥ í˜•ì‹ ì¶”ì¶œ ì™„ë£Œ")
    else:
        input_elem = soup.find('div', {'id': 'problem_input'})
        problem_info['input_format'] = input_elem.get_text(separator='\n', strip=True) if input_elem else ""
    
    # 3. ì¶œë ¥ ì„¤ëª…
    output_section = soup.find('section', {'id': 'output'})
    if output_section:
        problem_info['output_format'] = output_section.get_text(separator='\n', strip=True)
        print("  âœ… ì¶œë ¥ í˜•ì‹ ì¶”ì¶œ ì™„ë£Œ")
    else:
        output_elem = soup.find('div', {'id': 'problem_output'})
        problem_info['output_format'] = output_elem.get_text(separator='\n', strip=True) if output_elem else ""
    
    # 4. íŒíŠ¸
    hint_section = soup.find('section', {'id': 'hint'})
    if hint_section:
        problem_info['hint'] = hint_section.get_text(separator='\n', strip=True)
        print("  âœ… íŒíŠ¸ ì¶”ì¶œ ì™„ë£Œ")
    else:
        problem_info['hint'] = ""
    
    # 5. ì œí•œì‚¬í•­
    limit_elem = soup.find('div', {'id': 'problem_limit'})
    problem_info['limits'] = limit_elem.get_text(separator='\n', strip=True) if limit_elem else ""
    
    # 6. ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì¶”ì¶œ
    samples = []
    sample_count = 0
    
    for i in range(1, 20):
        input_section = soup.find('section', {'id': f'sampleinput{i}'})
        output_section = soup.find('section', {'id': f'sampleoutput{i}'})
        
        if input_section and output_section:
            input_pre = input_section.find('pre')
            output_pre = output_section.find('pre')
            
            if input_pre and output_pre:
                samples.append({
                    "input": input_pre.get_text(strip=True),
                    "output": output_pre.get_text(strip=True),
                })
                sample_count += 1
        else:
            input_elem = soup.find('pre', {'id': f'sample-input-{i}'})
            output_elem = soup.find('pre', {'id': f'sample-output-{i}'})
            
            if input_elem and output_elem:
                samples.append({
                    "input": input_elem.get_text(strip=True),
                    "output": output_elem.get_text(strip=True),
                })
                sample_count += 1
            else:
                break
    
    problem_info['samples'] = samples
    print(f"  âœ… ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ {sample_count}ê°œ ì¶”ì¶œ ì™„ë£Œ")
    
    return problem_info

def scrape_boj_with_requests(problem_id):
    """requests + BeautifulSoupì„ ì‚¬ìš©í•œ ì•ˆì •ì  ìŠ¤í¬ë˜í•‘"""
    print("  ğŸŒŠ requests + BeautifulSoup ìŠ¤í¬ë˜í•‘ ì‹œì‘...")
    
    try:
        url = f"https://www.acmicpc.net/problem/{problem_id}"
        
        # ë‹¤ì–‘í•œ User-Agentë¡œ ë¡œí…Œì´ì…˜
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
        
        import random
        selected_ua = random.choice(user_agents)
        
        # ì™„ì „í•œ ë¸Œë¼ìš°ì € í—¤ë” ì‹œë®¬ë ˆì´ì…˜
        headers = {
            'User-Agent': selected_ua,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Accept-Charset': 'utf-8',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0',
        }
        
        print(f"  â†’ ìš”ì²­ ì „ì†¡: {url}")
        print(f"  ğŸ”§ User-Agent: {selected_ua[:50]}...")
        
        # ì„¸ì…˜ì„ ì‚¬ìš©í•´ì„œ ì¿ í‚¤ ë° ì—°ê²° ìœ ì§€
        session = requests.Session()
        session.headers.update(headers)
        
        # ì¬ì‹œë„ ë¡œì§ ë‚´ì¥
        max_retries = 3
        for attempt in range(1, max_retries + 1):
            try:
                response = session.get(url, timeout=30, allow_redirects=True)
                response.raise_for_status()
                
                if response.status_code == 200:
                    print(f"  âœ… í˜ì´ì§€ ë¡œë“œ ì„±ê³µ (í¬ê¸°: {len(response.text):,} ë¬¸ì)")
                    
                    # í˜ì´ì§€ ìœ íš¨ì„± ê²€ì‚¬
                    if "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¬¸ì œ" in response.text:
                        print("  âŒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¬¸ì œ")
                        return None
                    
                    if len(response.text) < 1000:
                        print("  âŒ í˜ì´ì§€ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ")
                        return None
                    
                    # HTML íŒŒì‹±
                    problem_info = extract_problem_info_from_html(response.text)
                    
                    if problem_info and len(problem_info.get('samples', [])) > 0:
                        print(f"  ğŸ‰ requests ìŠ¤í¬ë˜í•‘ ì„±ê³µ! (ìƒ˜í”Œ {len(problem_info['samples'])}ê°œ)")
                        return problem_info
                    else:
                        print("  âš ï¸ ë¬¸ì œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨, ì¬ì‹œë„...")
                        if attempt < max_retries:
                            time.sleep(2)
                            continue
                        return None
                else:
                    print(f"  âŒ HTTP ì˜¤ë¥˜: {response.status_code}")
                    if attempt < max_retries:
                        time.sleep(2)
                        continue
                    return None
                    
            except requests.exceptions.RequestException as e:
                print(f"  âŒ ìš”ì²­ ì˜¤ë¥˜ (ì‹œë„ {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    time.sleep(3)
                    continue
                return None
            
    except Exception as e:
        print(f"  âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
        return None

def scrape_boj_with_retry(problem_id, max_attempts=3):
    """ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ requests ìŠ¤í¬ë˜í•‘"""
    print(f"  ğŸ”„ ì•ˆì •ì  ìŠ¤í¬ë˜í•‘ ì‹œì‘ (ìµœëŒ€ {max_attempts}íšŒ ì‹œë„)")
    
    for attempt in range(1, max_attempts + 1):
        print(f"\n  ğŸ“ ì‹œë„ {attempt}/{max_attempts}")
        
        if attempt > 1:
            delay = 2 * attempt  # 2ì´ˆ, 4ì´ˆ, 6ì´ˆ...
            print(f"  â³ {delay}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
            time.sleep(delay)
        
        result = scrape_boj_with_requests(problem_id)
        
        if result and len(result.get('samples', [])) > 0:
            print(f"  ğŸ‰ {attempt}ë²ˆì§¸ ì‹œë„ì—ì„œ ì„±ê³µ!")
            return result
        else:
            if attempt < max_attempts:
                print(f"  âŒ {attempt}ë²ˆì§¸ ì‹œë„ ì‹¤íŒ¨, ì¬ì‹œë„ ì¤€ë¹„...")
            else:
                print(f"  ğŸ’¥ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ({max_attempts}íšŒ)")
    
    return None

def main():
    parser = argparse.ArgumentParser(description='ë°±ì¤€ ë¬¸ì œ ì •ë³´ ìˆ˜ì§‘ (requests ë°©ì‹ - ì•ˆì •ì !)')
    parser.add_argument('--problem-id', required=True, help='ë°±ì¤€ ë¬¸ì œ ë²ˆí˜¸')
    parser.add_argument('--retry-mode', choices=['basic', 'aggressive'], default='basic', 
                       help='ì¬ì‹œë„ ëª¨ë“œ (basic: 3íšŒ, aggressive: 5íšŒ)')
    args = parser.parse_args()
    
    problem_id = args.problem_id
    is_github_actions = os.getenv('GITHUB_ACTIONS') == 'true'
    
    print(f"ğŸ“¥ ë¬¸ì œ {problem_id} ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
    
    if is_github_actions:
        print("ğŸ¤– GitHub Actions í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘")
        print("  ğŸŒŠ requests + BeautifulSoup ë°©ì‹ (ì•ˆì •ì !)")
        print("  âš¡ ë¹ ë¥´ê³  ê°€ë²¼ìš°ë©° í™•ì‹¤í•¨")
        print("  ğŸ”§ ë‹¤ì–‘í•œ User-Agent ë¡œí…Œì´ì…˜")
    else:
        print("ğŸ–¥ï¸ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘")
        print("  ğŸŒŠ requests + BeautifulSoup ë°©ì‹")
        print("  âš¡ Selenium ì—†ì´ë„ ì™„ë²½ ì‘ë™")
        print("  ğŸ”§ ê³ ê¸‰ í—¤ë” ì‹œë®¬ë ˆì´ì…˜")
    
    # 1. solved.ac APIë¡œ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
    print("\n  â†’ solved.ac API í˜¸ì¶œ...")
    solved_ac_info = get_solved_ac_info(problem_id)
    
    # 2. requests ë°©ì‹ìœ¼ë¡œ ìŠ¤í¬ë˜í•‘
    if args.retry_mode == 'aggressive':
        boj_info = scrape_boj_with_retry(problem_id, max_attempts=5)
    else:
        boj_info = scrape_boj_with_retry(problem_id, max_attempts=3)
    
    # 3. ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬
    if not boj_info:
        print("\n  âŒ ëª¨ë“  ìŠ¤í¬ë˜í•‘ ì‹œë„ ì‹¤íŒ¨")
        print("  ğŸ’¡ ë¬¸ì œ ì •ë³´ë¥¼ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•´ì£¼ì„¸ìš”:")
        print(f"     https://www.acmicpc.net/problem/{problem_id}")
        
        boj_info = {
            "description": f"ë¬¸ì œ {problem_id}ì˜ ìƒì„¸ ì„¤ëª…ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§í¬ì—ì„œ ì§ì ‘ í™•ì¸í•˜ì„¸ìš”.",
            "input_format": "ì…ë ¥ í˜•ì‹ì„ ì§ì ‘ í™•ì¸í•˜ì„¸ìš”.",
            "output_format": "ì¶œë ¥ í˜•ì‹ì„ ì§ì ‘ í™•ì¸í•˜ì„¸ìš”.",
            "limits": "ì‹œê°„/ë©”ëª¨ë¦¬ ì œí•œì„ ì§ì ‘ í™•ì¸í•˜ì„¸ìš”.",
            "hint": "",
            "samples": []
        }
        print(f"  âš ï¸ ë¹ˆ ìƒ˜í”Œ ë°ì´í„°ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    # 4. ìµœì¢… ì •ë³´ ì¡°í•©
    complete_info = {
        "problem_id": problem_id,
        "title": solved_ac_info.get("title", f"ë¬¸ì œ {problem_id}"),
        "level": solved_ac_info.get("level", "N/A"),
        "tags": solved_ac_info.get("tags", []),
        **boj_info
    }
    
    # 5. íŒŒì¼ ì €ì¥
    try:
        with open('problem_info.json', 'w', encoding='utf-8') as f:
            json.dump(complete_info, f, ensure_ascii=False, indent=2)
        
        sample_tests = {
            "problem_id": problem_id,
            "test_cases": complete_info['samples']
        }
        
        with open('sample_tests.json', 'w', encoding='utf-8') as f:
            json.dump(sample_tests, f, ensure_ascii=False, indent=2)
        
        environment = "GitHub Actions" if is_github_actions else "ë¡œì»¬"
        
        if len(complete_info['samples']) > 0:
            print(f"\nâœ… {environment} ìŠ¤í¬ë˜í•‘ ì™„ë£Œ:")
            print(f"  - ì œëª©: {complete_info['title']} (Level: {complete_info['level']})")
            print(f"  - íƒœê·¸: {', '.join(complete_info['tags']) if complete_info['tags'] else 'N/A'}")
            print(f"  - ìƒ˜í”Œ í…ŒìŠ¤íŠ¸: {len(complete_info['samples'])}ê°œ")
            print(f"  - íŒŒì¼: problem_info.json, sample_tests.json")
            print(f"  ğŸ‰ requests ë°©ì‹ì´ Seleniumë³´ë‹¤ í›¨ì”¬ ì•ˆì •ì ì´ë„¤ìš”!")
        else:
            print(f"\nâš ï¸ {environment} ì •ë³´ ìˆ˜ì§‘ ë¶€ë¶„ì  ì™„ë£Œ:")
            print(f"  - ì œëª©: {complete_info['title']} (Level: {complete_info['level']})")
            print(f"  - íƒœê·¸: {', '.join(complete_info['tags']) if complete_info['tags'] else 'N/A'}")
            print(f"  - ìƒ˜í”Œ í…ŒìŠ¤íŠ¸: 0ê°œ (ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨)")
            print(f"  - íŒŒì¼: problem_info.json, sample_tests.json")
            print(f"  âš ï¸ ì£¼ì˜: ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ê°€ ì—†ì–´ ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    except IOError as e:
        print(f"\nâŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()